steps:
  # Etapa 1: Construir a IMAGEM BASE (com todo o cÃ³digo)
  - name: 'gcr.io/cloud-builders/docker'
    args:
      [
        'build',
        '-t',
        'us-central1-docker.pkg.dev/${PROJECT_ID}/meu-repo-dataflow/etl-processing-hoteis-base:latest',
        '.',
      ]
    id: 'Build Base Image'

  # Etapa 2: Enviar (Push) a IMAGEM BASE
  - name: 'gcr.io/cloud-builders/docker'
    args:
      [
        'push',
        'us-central1-docker.pkg.dev/${PROJECT_ID}/meu-repo-dataflow/etl-processing-hoteis-base:latest',
      ]
    id: 'Push Base Image'
    waitFor: ['Build Base Image']

  # --- ETAPA 3: Construir o TEMPLATE da RAW ---
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # 1. Criar o ficheiro de metadados para a RAW
        echo '{
          "name": "Pipeline Hotelaria - RAW",
          "description": "Carrega dados da Transient (GCS) para a Raw (BigQuery) com upsert.",
          "metadata": {
            "mainFile": "pipeline_hotelaria/raw/main_raw.py"
          },
          "parameters": [
            { "name": "bq_project_id", "label": "Project ID", "helpText": "O ID do projeto GCP", "isOptional": false },
            { "name": "bq_dataset", "label": "BigQuery Dataset", "helpText": "Ex: raw_hotelaria", "isOptional": false },
            { "name": "input_subscription", "label": "PubSub Subscription", "helpText": "Subscription para trigger", "isOptional": true },
            { "name": "temp_location", "label": "Temp Location", "helpText": "Bucket para arquivos temporÃ¡rios", "isOptional": true }
          ]
        }' > raw_metadata.json

        # 2. Comando 'build' (que aponta para a imagem base)
        gcloud dataflow flex-template build gs://bk-etl-hotelaria/templates/pipeline_hotelaria_RAW.json \
          --image "us-central1-docker.pkg.dev/${PROJECT_ID}/meu-repo-dataflow/etl-processing-hoteis-base:latest" \
          --sdk-language "PYTHON" \
          --metadata-file "raw_metadata.json"
    id: 'Deploy RAW Template'
    waitFor: ['Push Base Image']

  # --- ETAPA 4: Construir o TEMPLATE da TRUSTED ---
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # 1. Criar o ficheiro de metadados para a TRUSTED
        echo '{
          "name": "Pipeline Hotelaria - TRUSTED",
          "description": "Carrega dados da Raw (BigQuery) para a Trusted (BigQuery) com transformaÃ§Ãµes.",
          "metadata": {
            "mainFile": "pipeline_hotelaria/trusted/main_trusted.py"
          },
          "parameters": [
            { "name": "bq_project_id", "label": "Project ID", "helpText": "O ID do projeto GCP", "isOptional": false },
            { "name": "bq_dataset", "label": "BigQuery Dataset", "helpText": "Ex: trusted_hotelaria", "isOptional": false },
            { "name": "input_subscription", "label": "PubSub Subscription", "helpText": "Subscription para trigger", "isOptional": true },
            { "name": "temp_location", "label": "Temp Location", "helpText": "Bucket para arquivos temporÃ¡rios", "isOptional": true }
          ]
        }' > trusted_metadata.json

        # 2. Comando 'build' (que aponta para a imagem base)
        gcloud dataflow flex-template build gs://bk-etl-hotelaria/templates/pipeline_hotelaria_TRUSTED.json \
          --image "us-central1-docker.pkg.dev/${PROJECT_ID}/meu-repo-dataflow/etl-processing-hoteis-base:latest" \
          --sdk-language "PYTHON" \
          --metadata-file "trusted_metadata.json"
    id: 'Deploy TRUSTED Template'
    waitFor: ['Push Base Image']

  # Etapa adicional para validar os templates
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "âœ… Validando templates criados..."
        gsutil ls gs://bk-etl-hotelaria/templates/pipeline_hotelaria_RAW.json && echo "âœ… RAW template vÃ¡lido"
        gsutil ls gs://bk-etl-hotelaria/templates/pipeline_hotelaria_TRUSTED.json && echo "âœ… TRUSTED template vÃ¡lido"
        
        # Verificar tamanho dos templates
        echo "ðŸ“Š Tamanho dos templates:"
        gsutil du -h gs://bk-etl-hotelaria/templates/pipeline_hotelaria_*.json
    id: 'Validate Templates'
    waitFor: ['Deploy RAW Template', 'Deploy TRUSTED Template']

# Define o local da imagem final
images:
  - 'us-central1-docker.pkg.dev/${PROJECT_ID}/meu-repo-dataflow/etl-processing-hoteis-base:latest'

# ConfiguraÃ§Ãµes de timeout
timeout: '1600s'

# Apenas logging no Cloud Logging
options:
  logging: CLOUD_LOGGING_ONLY